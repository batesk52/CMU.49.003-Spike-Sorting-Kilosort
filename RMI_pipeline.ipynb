{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Notebook Header Start -->\n",
    "\n",
    "<h1 align=\"center\">Spike Sorting</h1>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <strong>Author:</strong> Karl Bates<br>\n",
    "  <strong>Date:</strong> 2024-10-30<br>\n",
    "  <strong>Affiliation:</strong> Carnegie Mellon University, Cohen-Karni Group  || Neuromechatronics Lab\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“œ Project Overview\n",
    "\n",
    "(to populate) \n",
    "\n",
    "- **Objective:** (to populate)\n",
    "- **Scope:** (to populate)\n",
    "- **Libraries:** `Python`, `Pandas`, `SciPy`\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Š Notebook Outline\n",
    "\n",
    "1. **Data Import & Preprocessing**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“š References & Additional Resources\n",
    "\n",
    "- [Github: Kilosort4](https://github.com/MouseLand/Kilosort/tree/main)\n",
    "- [SpikeInterface](https://github.com/SpikeInterface)\n",
    "\n",
    "---\n",
    "\n",
    "<!-- Notebook Header End -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'RM1_pipeline'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m     12\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../automations\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mRM1_pipeline\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprobeinterface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m write_prb\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Download channel maps for default probes\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'RM1_pipeline'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec, rcParams\n",
    "import sys\n",
    "sys.path.insert(1, '../automations')\n",
    "import RM1\n",
    "\n",
    "from probeinterface import write_prb\n",
    "# Download channel maps for default probes\n",
    "from kilosort.utils import download_probes\n",
    "from probeinterface.plotting import plot_probe, plot_probe_group\n",
    "from probeinterface import Probe, get_probe, generate_linear_probe\n",
    "\n",
    "from spikeinterface.extractors import read_intan\n",
    "\n",
    "from kilosort import run_kilosort\n",
    "from kilosort import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "RAT_NAME = 'DW322'\n",
    "STIMULATION = 'DRGS_2_240918_130024'\n",
    "DATA_DIRECTORY = Path(fr'D:\\Data\\CMU.80 Data\\88 Analyzed Data\\88.001 Kilosort on DW322')  # NOTE Specify the path where the data will be copied to, and where Kilosort4 results will be saved.\n",
    "# Create path if it doesn't exist\n",
    "DATA_DIRECTORY.mkdir(parents=True, exist_ok=True)\n",
    "PROBE_DIRECTORY = Path(r'D:\\Data\\CMU.80 Data\\88 Analyzed Data\\88.001 Kilosort on DW322\\A1x32-Edge-5mm-20-177-A32.prb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining filepath for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: You will need to select the appropriate data stream. If you run without\n",
    "#       specifying `stream_id`, you will get an error message explaining what\n",
    "#       each stream corresponds to.\n",
    "filepath = Path(f\"D:\\Data\\CMU.80 Data\\82 External Data\\82.002 Sample Rat Data from RM1 Project\\DW322\\{RAT_NAME}\\{STIMULATION}\\{STIMULATION}.rhd\")\n",
    "recording = read_intan(filepath, stream_id='0')\n",
    "recording"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no probe information is given with this data, so we will need to define it or assign one from the probe interface library.\n",
    "\n",
    "I will first show how to create the binary file using `Spike Interface` and numpy's `memmap()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all channel IDs\n",
    "channel_ids = recording.get_channel_ids()\n",
    "\n",
    "# Identify channels that start with 'B'\n",
    "channels_to_remove = [ch for ch in channel_ids if ch.startswith('B')]\n",
    "\n",
    "# Remove those channels from the recording\n",
    "recording = recording.remove_channels(channels_to_remove)\n",
    "\n",
    "# Verify the channels have been removed\n",
    "print(recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and probe using `SpikeInterface`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Data will be saved as np.int16 by default since that is the standard\n",
    "#       for ephys data. If you need a different data type for whatever reason\n",
    "#       such as `np.uint16`, be sure to update this.\n",
    "dtype = np.int16\n",
    "filename, N, c, s, fs, probe_path = io.spikeinterface_to_binary(\n",
    "    recording, DATA_DIRECTORY, data_name=f'{RAT_NAME}_{STIMULATION}_data.bin', dtype=dtype,\n",
    "    chunksize=60000, export_probe=True, probe_name='probe.prb'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this code will complete, but because there is no probe associated with the data, I will need to define one later on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and probe using `Numpy memmap`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining ouput file and loading data into binary in chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output binary file\n",
    "output_file = DATA_DIRECTORY / f'{RAT_NAME}_{STIMULATION}_data_memmap.bin'\n",
    "\n",
    "# Get data shape\n",
    "num_channels = recording.get_num_channels()\n",
    "num_samples = recording.get_num_frames()\n",
    "\n",
    "# Create a memory-mapped file without using `with`\n",
    "data_dtype = np.int16  # This is typically the standard for electrophysiology data\n",
    "memmap_file = np.memmap(output_file, dtype=data_dtype, mode='w+', shape=(num_samples, num_channels))\n",
    "\n",
    "# Define the chunk size for processing (e.g., 60,000 samples at a time)\n",
    "chunk_size = 60000\n",
    "\n",
    "# Loop through the data and write to the binary file in chunks\n",
    "for start_idx in range(0, num_samples, chunk_size):\n",
    "    end_idx = min(start_idx + chunk_size, num_samples)\n",
    "    \n",
    "    # Extract data chunk from the RecordingExtractor\n",
    "    data_chunk = recording.get_traces(start_frame=start_idx, end_frame=end_idx)\n",
    "    \n",
    "    # Write the chunk to the memory-mapped file\n",
    "    memmap_file[start_idx:end_idx, :] = data_chunk.astype(data_dtype)\n",
    "\n",
    "# Explicitly flush changes to disk\n",
    "memmap_file.flush()\n",
    "\n",
    "print(f\"Data successfully saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exporting probe data\n",
    "\n",
    "this will NOT run correctly, since there is no probe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Get the probe from the recording (if available)\n",
    "# probe = recording.get_probe()\n",
    "\n",
    "# # Define the path to save the probe configuration\n",
    "# probe_path = DATA_DIRECTORY / 'probe.prb'\n",
    "\n",
    "# # Save the probe configuration\n",
    "# write_prb(probe_path, probe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining or assigning a probe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## downloading standard probes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can use the `ProbeInterface` repository to define a standard probe.\n",
    "\n",
    "You can then pull a probe from the `ProbeInterface` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manufacturer = 'neuronexus'\n",
    "probe_name = 'A1x32-Poly3-10mm-50-177'\n",
    "\n",
    "probe = get_probe(manufacturer, probe_name)\n",
    "print(probe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but, this is not the probe we are using. Instead, we are using a `A1x32-Edge-5mm-20-177-A32`\n",
    "\n",
    "This is not in the library, so I will have to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defining a probe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following parameters came from this website:\n",
    "\n",
    "[Neuronexus Penetrating Probe Catalog](https://19885756.fs1.hubspotusercontent-na1.net/hubfs/19885756/Penetrating_probe_catalog_V1.8.pdf#page=1.06&gsr=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the spreadsheet, `Adapter_pinout.xlsx`, the contact ID's can be traced to the \"device channel\", and we can assign them on the probe. \n",
    "\n",
    "In this case, our channel indices correspond to the aux inputs to the intan headstage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_mapping = pd.read_excel(\"Adapter_pinout.xlsx\",sheet_name=\"summary\",header=2).iloc[:,[8,10,12,14]]\n",
    "channel_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the channel indices shall be the `Intan.1` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_probe = generate_linear_probe(num_elec=32, ypitch=20)\n",
    "\n",
    "# Define the number of channels and their positions along the probe shank\n",
    "num_channels = 32\n",
    "positions = [\n",
    "    (0, i * 20) for i in range(num_channels)\n",
    "]  # Channel spacing in micrometers\n",
    "\n",
    "# Create a Probe object\n",
    "linear_probe = Probe(ndim=2, si_units='um')\n",
    "linear_probe.set_contacts(positions=positions, shapes='rect', shape_params={'width': 18,\"height\":10})\n",
    "\n",
    "# Assign electrical connections based on the connector diagram\n",
    "linear_probe.set_contact_ids(np.arange(1, 33)) # I set the first input to 1, instead of Python's traditional 0, to match the connector diagram\n",
    "\n",
    "\n",
    "linear_probe.set_device_channel_indices(channel_mapping['Intan Input.1'][::-1]) # the [::-1] is to reverse the order\n",
    "\n",
    "# first plot: contact ids on the probe itself\n",
    "plot_probe(linear_probe, with_device_index=False,with_contact_id=True)\n",
    "\n",
    "# second plot: device ids on the probe; when the intan reads, say, \"dev14\", it means that it's the 1st input on the electrode probe (in graph 1)\n",
    "plot_probe(linear_probe, with_device_index=True,with_contact_id=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_probe.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving the probe - SpikeInterface Style\n",
    "\n",
    "here, you'll use the `write_probeinterface` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from probeinterface import write_probeinterface\n",
    "\n",
    "# Assuming 'linear_probe' is your defined Probe object\n",
    "output_path = os.path.join(DATA_DIRECTORY, \"A1x32-Edge-5mm-20-177-A32.json\")  # Specify your output JSON file path\"A1x32-Edge-5mm-20-177-A32.json\" \n",
    "write_probeinterface(output_path, linear_probe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving the probe - Kilosort 4 Style\n",
    "\n",
    "to be able to use with Kilosort, you'll need to export the probe as a prb file using `write_prb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from probeinterface import ProbeGroup, write_prb\n",
    "# Multiple probes can be added to a ProbeGroup. We only have one, but a\n",
    "# ProbeGroup wrapper is still necessary for `write_prb` to work.\n",
    "pg = ProbeGroup()\n",
    "pg.add_probe(linear_probe)\n",
    "# CHANGE THIS PATH to wherever you want to save your probe file.\n",
    "write_prb('A1x32-Edge-5mm-20-177-A32.prb', pg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Kilosort4\n",
    "\n",
    "At this point, it's a good idea to open the Kilosort gui and check that the\n",
    "data and probe appear to have been loaded correctly and no settings need to be\n",
    "tweaked. You will need to input the path to the binary datafile, the folder where\n",
    "results should be saved, and select a probe file.\n",
    "\n",
    "```conda activate kilosort```\n",
    "\n",
    "```python -m kilosort```\n",
    "\n",
    "From there, you can either launch Kilosort using the GUI or run the\n",
    "next notebook cell to run it through the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from kilosort import run_kilosort, DEFAULT_SETTINGS\n",
    "\n",
    "settings = DEFAULT_SETTINGS\n",
    "\n",
    "\n",
    "# NOTE: 'n_chan_bin' is a required setting, and should reflect the total number\n",
    "#       of channels in the binary file. For information on other available\n",
    "#       settings, see `kilosort.run_kilosort.default_settings`.\n",
    "settings = {'data_dir': DATA_DIRECTORY, 'n_chan_bin': 34}\n",
    "\n",
    "ops, st, clu, tF, Wall, similar_templates, is_ref, est_contam_rate, kept_spikes = \\\n",
    "    run_kilosort(\n",
    "        settings=settings, probe_name=PROBE_DIRECTORY,\n",
    "        # save_preprocessed_copy=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs saved to results_dir\n",
    "results_dir = Path(settings['data_dir']).joinpath('kilosort4')\n",
    "ops = np.load(results_dir / 'ops.npy', allow_pickle=True).item()\n",
    "camps = pd.read_csv(results_dir / 'cluster_Amplitude.tsv', sep='\\t')['Amplitude'].values\n",
    "contam_pct = pd.read_csv(results_dir / 'cluster_ContamPct.tsv', sep='\\t')['ContamPct'].values\n",
    "chan_map =  np.load(results_dir / 'channel_map.npy')\n",
    "templates =  np.load(results_dir / 'templates.npy')\n",
    "chan_best = (templates**2).sum(axis=1).argmax(axis=-1)\n",
    "chan_best = chan_map[chan_best]\n",
    "amplitudes = np.load(results_dir / 'amplitudes.npy')\n",
    "st = np.load(results_dir / 'spike_times.npy')\n",
    "clu = np.load(results_dir / 'spike_clusters.npy')\n",
    "firing_rates = np.unique(clu, return_counts=True)[1] * 30000 / st.max()\n",
    "dshift = ops['dshift']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec, rcParams\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['axes.spines.right'] = False\n",
    "gray = .5 * np.ones(3)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10), dpi=100)\n",
    "grid = gridspec.GridSpec(3, 3, figure=fig, hspace=0.5, wspace=0.5)\n",
    "\n",
    "ax = fig.add_subplot(grid[0,0])\n",
    "ax.plot(np.arange(0, ops['Nbatches'])*2, dshift);\n",
    "ax.set_xlabel('time (sec.)')\n",
    "ax.set_ylabel('drift (um)')\n",
    "\n",
    "ax = fig.add_subplot(grid[0,1:])\n",
    "t0 = 0\n",
    "t1 = np.nonzero(st > ops['fs']*5)[0][0]\n",
    "ax.scatter(st[t0:t1]/30000., chan_best[clu[t0:t1]], s=0.5, color='k', alpha=0.25)\n",
    "ax.set_xlim([0, 5])\n",
    "ax.set_ylim([chan_map.max(), 0])\n",
    "ax.set_xlabel('time (sec.)')\n",
    "ax.set_ylabel('channel')\n",
    "ax.set_title('spikes from units')\n",
    "\n",
    "ax = fig.add_subplot(grid[1,0])\n",
    "nb=ax.hist(firing_rates, 20, color=gray)\n",
    "ax.set_xlabel('firing rate (Hz)')\n",
    "ax.set_ylabel('# of units')\n",
    "\n",
    "ax = fig.add_subplot(grid[1,1])\n",
    "nb=ax.hist(camps, 20, color=gray)\n",
    "ax.set_xlabel('amplitude')\n",
    "ax.set_ylabel('# of units')\n",
    "\n",
    "ax = fig.add_subplot(grid[1,2])\n",
    "nb=ax.hist(np.minimum(100, contam_pct), np.arange(0,105,5), color=gray)\n",
    "ax.plot([10, 10], [0, nb[0].max()], 'k--')\n",
    "ax.set_xlabel('% contamination')\n",
    "ax.set_ylabel('# of units')\n",
    "ax.set_title('< 10% = good units')\n",
    "\n",
    "for k in range(2):\n",
    "    ax = fig.add_subplot(grid[2,k])\n",
    "    is_ref = contam_pct<10.\n",
    "    ax.scatter(firing_rates[~is_ref], camps[~is_ref], s=3, color='r', label='mua', alpha=0.25)\n",
    "    ax.scatter(firing_rates[is_ref], camps[is_ref], s=3, color='b', label='good', alpha=0.25)\n",
    "    ax.set_ylabel('amplitude (a.u.)')\n",
    "    ax.set_xlabel('firing rate (Hz)')\n",
    "    ax.legend()\n",
    "    if k==1:\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_title('loglog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = ops['probe']\n",
    "# x and y position of probe sites\n",
    "xc, yc = probe['xc'], probe['yc']\n",
    "nc = 16 # number of channels to show\n",
    "good_units = np.nonzero(contam_pct <= 0.1)[0]\n",
    "mua_units = np.nonzero(contam_pct > 0.1)[0]\n",
    "\n",
    "\n",
    "gstr = ['good', 'mua']\n",
    "for j in range(2):\n",
    "    print(f'~~~~~~~~~~~~~~ {gstr[j]} units ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('title = number of spikes from each unit')\n",
    "    units = good_units if j==0 else mua_units \n",
    "    fig = plt.figure(figsize=(12,3), dpi=150)\n",
    "    grid = gridspec.GridSpec(2,20, figure=fig, hspace=0.25, wspace=0.5)\n",
    "\n",
    "    for k in range(40):\n",
    "        wi = units[np.random.randint(len(units))]\n",
    "        wv = templates[wi].copy()  \n",
    "        cb = chan_best[wi]\n",
    "        nsp = (clu==wi).sum()\n",
    "        \n",
    "        ax = fig.add_subplot(grid[k//20, k%20])\n",
    "        n_chan = wv.shape[-1]\n",
    "        ic0 = max(0, cb-nc//2)\n",
    "        ic1 = min(n_chan, cb+nc//2)\n",
    "        wv = wv[:, ic0:ic1]\n",
    "        x0, y0 = xc[ic0:ic1], yc[ic0:ic1]\n",
    "\n",
    "        amp = 4\n",
    "        for ii, (xi,yi) in enumerate(zip(x0,y0)):\n",
    "            t = np.arange(-wv.shape[0]//2,wv.shape[0]//2,1,'float32')\n",
    "            t /= wv.shape[0] / 20\n",
    "            ax.plot(xi + t, yi + wv[:,ii]*amp, lw=0.5, color='k')\n",
    "\n",
    "        ax.set_title(f'{nsp}', fontsize='small')\n",
    "        ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kilosort",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
