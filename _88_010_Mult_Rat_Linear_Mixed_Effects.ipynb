{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Notebook Header Start -->\n",
    "\n",
    "<h1 align=\"center\">Changes to Noxious Stimuli by means of Dorsal Root Ganglion Stimulation</h1>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <strong>Author:</strong> Karl Bates<br>\n",
    "  <strong>Date:</strong> 2024-12-06<br>\n",
    "  <strong>Affiliation:</strong> Carnegie Mellon University, Cohen-Karni Lab  || Neuromechatronics Lab\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## üìä Notebook Outline\n",
    "\n",
    "* **Importing libraries & data**\n",
    "* **Preprocess neurophysiology recordings for spike sorting**\n",
    "* **Package preprocessed data for spike sorting using Kilosort4**\n",
    "* **Run Kilosort to extract spike activity**\n",
    "* **Calculate average firing rate of each cluster during noxious stimuli**\n",
    "* **Compare the firing rates of clusters before and after noxious stimuli**\n",
    "\n",
    "## üìö References & Additional Resources\n",
    "\n",
    "- [Kilosort4 docs](https://github.com/MouseLand/Kilosort/tree/main)\n",
    "- [SpikeInterface docs](https://github.com/SpikeInterface)\n",
    "\n",
    "---\n",
    "\n",
    "<!-- Notebook Header End -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚û° Importing Libraries & Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "from kilosort import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import math\n",
    "import seaborn as sns\n",
    "from patsy import dmatrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# custom imports\n",
    "from automations import RM1\n",
    "from automations import SpikeInterface_wrapper\n",
    "from automations import Kilosort_wrapper\n",
    "from automations import plots\n",
    "from automations import analysis_functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### probe definition\n",
    "\n",
    "Using the spreadsheet, `Adapter_pinout.xlsx`, the contact ID's can be traced to the \"device channel\", and we can assign them on the probe. \n",
    "\n",
    "In this case, our channel indices correspond to the aux inputs to the intan headstage.\n",
    "\n",
    "refer to the notebook, `RM1_pipeline.ipynb` within  the `dev_notebook` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBE_DIRECTORY = Path(r'D:\\SynologyDrive\\CMU.80 Data\\88 Analyzed Data\\88.001 A1x32-Edge-5mm-20-177-A32\\A1x32-Edge-5mm-20-177-A32.prb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filepath definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE Specify the path where the data will be copied to, and where Kilosort4 results will be saved.\n",
    "# in this case, the data is saved in a folder with multiple rats\n",
    "DATA_DIRECTORY = Path(fr'D:\\SynologyDrive\\CMU.80 Data\\82 External Data\\82.002 Sample Rat Data from RM1 Project')  \n",
    "# Create path if it doesn't exist\n",
    "DATA_DIRECTORY.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# NOTE Specify the path where the data will be copied to, and where Kilosort4 results will be saved.\n",
    "# save data to the inbox; make sure that the folders: binary & figures exist\n",
    "\n",
    "# select your path\n",
    "\n",
    "# the following save directory has already been run, and it stores data that has been unaltered\n",
    "SAVE_DIRECTORY = Path(fr\"D:\\SynologyDrive\\CMU.80 Data\\88 Analyzed Data\\88.010 Mult_Rat_Linear_Mixed_Effects\")\n",
    "\n",
    "# Create paths if they don't exist\n",
    "SAVE_DIRECTORY.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run a multi-rat class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rats = [RM1.Rat(DATA_DIRECTORY, PROBE_DIRECTORY, rat_id) for rat_id in ['DW322', 'DW323', 'DW327']]\n",
    "group = RM1.RatGroup(rats)\n",
    "group.run_preprocessing()  # preprocess all rats at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group.rats.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run spikeinterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_wrappers = group.create_spikeinterface_wrappers(SAVE_DIRECTORY)\n",
    "for rat_id in si_wrappers.keys():\n",
    "    # si_wrappers[rat_id].save_spinalcord_data_to_binary()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kilosort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_wrappers = group.create_kilosort_wrappers(SAVE_DIRECTORY, probe_directory=PROBE_DIRECTORY)\n",
    "def my_custom_criteria(cluster_labels, st, clu, est_contam_rate, fs):\n",
    "    # Example criteria: Contamination rate < 0.2 and firing rate between 0.5 and 50 Hz\n",
    "    contam_good = est_contam_rate < 0.2\n",
    "    fr_good = np.zeros(cluster_labels.size, dtype=bool)\n",
    "    for i, c in enumerate(cluster_labels):\n",
    "        spikes = st[clu == c]\n",
    "        fr = spikes.size / ((spikes.max() - spikes.min()) / fs)\n",
    "        if 0.5 <= fr <= 50:\n",
    "            fr_good[i] = True\n",
    "    return np.logical_and(contam_good, fr_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rat_id in ks_wrappers.keys():\n",
    "    # ks_wrappers[rat_id].run_kilosort_trial_summary(new_settings=\"vf_settings\",custom_criteria=my_custom_criteria)\n",
    "    ks_wrappers[rat_id].extract_kilosort_outputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate sanity plots for each trial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw322_trials = [\"VF_1_240918_143256\",\"VF_2_240918_143936\",\"VF_3_240918_144658\",\"VF_4_240918_145638\",\"VF_5_240918_150137\",\"VF_6_240918_150811\",\"VF_7_240918_151516\",\"VF_8_240918_152056\",\"VF_9_240918_152753\"]\n",
    "dw323_trials = [\"VF_1_240911_164342\",\"VF_2_240911_165039\",\"VF_3_240911_165617\",\"VF_4_240911_170446\",\"VF_5_240911_171014\",\"VF_6_240911_171505\"]\n",
    "dw327_trials = [\"VF_1_241125_153746\",\"VF_2_241125_154307\",\"VF_3_241125_154841\",\"VF_4_241125_155417\",\"VF_5_241125_155941\",\"VF_6_241125_160515\",\"VF_7_241125_161126\",\"VF_8_241125_161626\",\"VF_9_241125_162141\",\"VF_10_241125_162725\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOTE:\n",
    "\n",
    "seeing repeating units is not a sign that there is an issue: these plots a pick random units, (40) times, to show how spikes are captured on the probe. \n",
    "\n",
    "the fewer the number of good or mua units, the more likely there will be repeated units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DW322"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_wrappers[\"DW322\"].plot_trial_results(dw322_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DW323"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_wrappers[\"DW323\"].plot_trial_results(dw323_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DW327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_wrappers[\"DW327\"].plot_trial_results(dw327_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot characteristic waveform for each neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DW322"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_wrappers[\"DW322\"].plot_cluster_waveforms(dw322_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DW323"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_wrappers[\"DW323\"].plot_cluster_waveforms(dw323_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DW3237"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_wrappers[\"DW327\"].plot_cluster_waveforms(dw327_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi-animal von frey analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multi‚Äìrat analysis instance.\n",
    "multi_analysis = analysis_functions.MultiRatVonFreyAnalysis(group, si_wrappers, ks_wrappers)\n",
    "\n",
    "# combine all the trials from every animal to plot the results\n",
    "\n",
    "combined_results = multi_analysis.analyze_all_trials(excel_parent_folder=SAVE_DIRECTORY, subwindow_width=0.5, corr_threshold=0.1)\n",
    "\n",
    "# use combined_results for further plotting or modeling.\n",
    "\n",
    "# combined_results now contains results from each rat, loaded from Excel if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results[\"DW322_VF_2_240918_143936\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the Results and Metadata:\n",
    "You would need to create (or extract) a DataFrame where each row corresponds to a sub-window (or trial) with columns for the dependent variable (for example, average voltage), the fixed effects (e.g. stimulation, pulse width, waiting), and a column indicating the animal (rat ID). You might need to merge your VonFreyAnalysis results with metadata that specifies stimulation parameters.\n",
    "\n",
    "Fit a Mixed Effects Model:\n",
    "Use the statsmodels MixedLM or the formula interface (statsmodels.formula.api.mixedlm) to specify a model with fixed effects for voltage, stimulation, pulse width, waiting and a random intercept for animal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example of single-rat experiment properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group.rats[\"DW323\"].qst_trial_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combining the experiment notes for individual animals, for combined plots and linear mixed effects modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_unique_cols(df):\n",
    "    new_cols = []\n",
    "    seen = {}\n",
    "    for col in df.columns:\n",
    "        if col in seen:\n",
    "            seen[col] += 1\n",
    "            new_cols.append(f\"{col}_{seen[col]}\")\n",
    "        else:\n",
    "            seen[col] = 0\n",
    "            new_cols.append(col)\n",
    "    df.columns = new_cols\n",
    "    return df\n",
    "\n",
    "dfs = []\n",
    "for rat_id, rat in group.rats.items():\n",
    "    df = make_unique_cols(rat.qst_trial_notes.copy())\n",
    "    df['Rat ID'] = rat_id\n",
    "    df[\"Trial Number\"] = rat_id + \"_\" + df[\"Trial Number\"].astype(str)\n",
    "    dfs.append(df)\n",
    "\n",
    "combined_qst_notes = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Sort keys based on the numeric part after the second underscore (i.e., the zero-padded trial number)\n",
    "sorted_keys = sorted(\n",
    "    combined_results.keys(),\n",
    "    key=lambda x: int(x.split('_')[2])\n",
    ")\n",
    "\n",
    "combined_qst_notes['Trial_ID'] = sorted_keys\n",
    "\n",
    "# After concatenating your DataFrames into combined_qst_notes:\n",
    "combined_qst_notes['Trial_ID'] = list(combined_results.keys())\n",
    "combined_qst_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot a composite Von Frey Analysis plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example:\n",
    "plots.vf_all_trials_combined_plot(combined_results, combined_qst_notes,corr_threshold=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine metadata and neuron firing changes for linear effects mixed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_and_filter_by_corr(combined_results, combined_qst_notes, corr_threshold=0.1):\n",
    "    \"\"\"\n",
    "    Flattens trial data into a single DataFrame, then filters clusters by correlation threshold.\n",
    "    Only clusters whose absolute correlation meets or exceeds corr_threshold are kept.\n",
    "    \"\"\"\n",
    "    # Create dictionaries for columns you need from combined_qst_notes\n",
    "    freq_dict = dict(zip(combined_qst_notes['Trial_ID'], combined_qst_notes['Freq. (Hz)']))\n",
    "    amp_dict = dict(zip(combined_qst_notes['Trial_ID'], combined_qst_notes['amp']))\n",
    "    # Add a rat_id_dict to capture the rat ID from combined_qst_notes\n",
    "    rat_id_dict = dict(zip(combined_qst_notes['Trial_ID'], combined_qst_notes['Rat ID']))\n",
    "    pulse_width_dict = dict(zip(combined_qst_notes['Trial_ID'], combined_qst_notes['PW (us)']))\n",
    "\n",
    "\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for trial_id, res in combined_results.items():\n",
    "        # Get frequency and amplitude\n",
    "        freq_hz = freq_dict.get(trial_id)\n",
    "        amp_val = amp_dict.get(trial_id)\n",
    "        rat_id = rat_id_dict.get(trial_id)\n",
    "        pulse_width = pulse_width_dict.get(trial_id)\n",
    "\n",
    "        if freq_hz is None or amp_val is None or rat_id is None or pulse_width is None:\n",
    "            continue\n",
    "\n",
    "        avg_voltage_df = res.get('voltage_df')\n",
    "        firing_rates_df = res.get('firing_df')\n",
    "        if avg_voltage_df is None or firing_rates_df is None:\n",
    "            continue\n",
    "        \n",
    "        # Skip if not enough rows to have correlation data\n",
    "        if len(firing_rates_df) < 2:\n",
    "            continue\n",
    "\n",
    "        # Extract the correlation row (second-to-last row)\n",
    "        correlation_data = firing_rates_df.iloc[-2]\n",
    "        # Convert correlation entries to a dictionary keyed by integer cluster IDs\n",
    "        corr_dict = {\n",
    "            int(k): v\n",
    "            for k, v in correlation_data.to_dict().items()\n",
    "            if str(k).isdigit()\n",
    "        }\n",
    "\n",
    "        # Exclude the last two rows (correlation row, plus any extra row if present)\n",
    "        firing_data = firing_rates_df.iloc[:-2]\n",
    "\n",
    "        # Melt the firing data to long format: (group, cluster, firing_rate)\n",
    "        firing_melt = firing_data.melt(\n",
    "            id_vars=['group'], \n",
    "            var_name='cluster', \n",
    "            value_name='firing_rate'\n",
    "        )\n",
    "        firing_melt['cluster'] = pd.to_numeric(firing_melt['cluster'], errors='coerce')\n",
    "\n",
    "        # Merge firing data with average voltage on group\n",
    "        if \"avg_voltage\" not in avg_voltage_df.columns:\n",
    "            continue\n",
    "        merged_df = pd.merge(\n",
    "            firing_melt,\n",
    "            avg_voltage_df[[\"group\", \"avg_voltage\"]],\n",
    "            on=\"group\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "\n",
    "        # Map correlation values per cluster\n",
    "        merged_df['correlation'] = merged_df['cluster'].map(corr_dict)\n",
    "\n",
    "        # Add identifying columns\n",
    "        merged_df['Trial_ID'] = trial_id\n",
    "        merged_df['Frequency_Hz'] = freq_hz\n",
    "        merged_df['Amplitude'] = amp_val\n",
    "        merged_df[\"Pulse_Width(us)\"] = pulse_width\n",
    "        # normalize the results by dividing by average voltage\n",
    "        merged_df[\"firing_rate_vs_stim(uV^-1)\"] = merged_df['Frequency_Hz'] / merged_df[\"avg_voltage\"]\n",
    "        merged_df['Rat_ID'] = rat_id\n",
    "\n",
    "        # if I need to further flatten the dataset\n",
    "        merged_df['cluster'] = merged_df['cluster'].astype(str) + \"-\" + merged_df[\"Trial_ID\"].astype(str)\n",
    "        \n",
    "        # Collect all in a list\n",
    "        records.append(merged_df)\n",
    "\n",
    "    # Combine all into a single DataFrame\n",
    "    if not records:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    final_long_df = pd.concat(records, ignore_index=True)\n",
    "\n",
    "    # Filter by correlation threshold. Keep only those meeting abs corr >= threshold\n",
    "    final_long_df = final_long_df[final_long_df['correlation'].abs() >= corr_threshold]\n",
    "\n",
    "    return final_long_df\n",
    "\n",
    "\n",
    "lmem = flatten_and_filter_by_corr(combined_results, combined_qst_notes, corr_threshold=0.01)\n",
    "lmem.to_csv(SAVE_DIRECTORY / \"flattened_data.csv\")\n",
    "lmem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting a better look at the force distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# histogram\n",
    "\n",
    "pre_data = lmem[lmem['group'] == 'pre-stim']['avg_voltage']\n",
    "post_data = lmem[lmem['group'] == 'post-stim']['avg_voltage']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(pre_data, bins=30, alpha=0.5, label='pre-stim', edgecolor='black')\n",
    "plt.hist(post_data, bins=30, alpha=0.5, label='post-stim', edgecolor='black')\n",
    "plt.title('Histogram of Average Voltage: pre vs post stim')\n",
    "plt.xlabel('Average Voltage')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# boxplot\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "data_to_plot = [\n",
    "    pre_data,\n",
    "    post_data\n",
    "]\n",
    "plt.boxplot(data_to_plot, labels=['pre-stim', 'post-stim'])\n",
    "plt.title('Box Plot of Average Voltage: pre vs post stim')\n",
    "plt.ylabel('Average Voltage')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it honestly doesn't look too different - what could the issue be??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grouping the dataset by \"bins\" of stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Define bin edges: we go from 0 to slightly above the max value in steps of 50,000.\n",
    "max_val = lmem['avg_voltage'].max()\n",
    "bin_edges = np.arange(0, max_val + 50000, 50000)\n",
    "\n",
    "# 2. Create labels that match the upper bound of each bin.\n",
    "#    For instance, bin [0, 50000] gets the label \"50000\", bin (50000, 100000] gets \"100000\", etc.\n",
    "labels = [str(int(x)) for x in bin_edges[1:]]\n",
    "\n",
    "# 3. Use pd.cut to discretize avg_voltage. \n",
    "#    include_lowest=True ensures that 0 goes into the first bin. \n",
    "#    With right=True (the default), intervals are (a, b], so 50,000 falls in the first bin.\n",
    "lmem['voltage_bin'] = pd.cut(lmem['avg_voltage'], \n",
    "                           bins=bin_edges, \n",
    "                           labels=labels, \n",
    "                           include_lowest=True,\n",
    "                           right=True)\n",
    "\n",
    "# Now each row has a \"voltage_bin\" indicating its bin.\n",
    "\n",
    "\n",
    "# see bin counts\n",
    "bin_counts = lmem['voltage_bin'].value_counts().sort_index()\n",
    "print(\"Number of entries in each bin (uV):\")\n",
    "print(bin_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'cluster' and 'voltage_bin' then calc mean firing rate\n",
    "avg_firing_rate = lmem.groupby(['Rat_ID',\"Trial_ID\",'cluster', 'voltage_bin', \"Frequency_Hz\", 'group'])['firing_rate'].mean().reset_index().dropna()\n",
    "# avg_firing_rate[\"firing_rate\"] = avg_firing_rate[\"firing_rate\"].astype(float) # I think it already does this, no need to specify againa\n",
    "avg_firing_rate.to_csv(SAVE_DIRECTORY / \"grouped_stimulus.csv\")\n",
    "avg_firing_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT: this code need to drop zero entries, because you can't calculate % change with zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the data so that pre-stim and post-stim firing rates become separate columns.\n",
    "pre_post_pivot = avg_firing_rate.pivot_table(index=['Rat_ID', 'Trial_ID', 'cluster', 'voltage_bin', 'Frequency_Hz'],\n",
    "                          columns='group',\n",
    "                          values='firing_rate').reset_index()\n",
    "\n",
    "\n",
    "# Remove rows where pre-stim is zero to avoid division by zero\n",
    "pre_post_pivot = pre_post_pivot[pre_post_pivot['pre-stim'] != 0]\n",
    "\n",
    "\n",
    "# Drop rows that do not have both pre-stim and post-stim values\n",
    "pre_post_pivot = pre_post_pivot.dropna(subset=['pre-stim', 'post-stim'])\n",
    "\n",
    "# Calc percent change, pre to post\n",
    "pre_post_pivot['percent_change'] = ((pre_post_pivot['post-stim'] - pre_post_pivot['pre-stim']) / pre_post_pivot['pre-stim']) * 100\n",
    "\n",
    "pre_post_pivot.to_csv(SAVE_DIRECTORY / \"percent_change.csv\")\n",
    "\n",
    "pre_post_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìà linear mixed effects model - nested cluster, trial, rat id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE SURE TO DO THIS STEP\n",
    "\n",
    "\n",
    "when you filter by correlation threshhold, it is going to drop rows and some of the data may refer to old indices.  This can happen if you drop rows (for example, due to missing percent_change values) without resetting the index, so some groups still reference old index values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this graph is hard to draw any conclusions from - plot the average trend, with std error bars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #### structure of dataset\n",
    "\n",
    "    * Rat\n",
    "        * trial \n",
    "            * cluster ID\n",
    "\n",
    "    #### Predictor/Fixed Variable:\n",
    "    * Frequency_Hz (categorical: 5, 20, 100 Hz): frequency of DRG stimulation\n",
    "    #### Random Effects:\n",
    "    * Rat_ID: Differences in baseline firing changes between animals.\n",
    "    * Trial_ID (nested within Rat_ID): Trial‚Äêto‚Äêtrial variability (per animal).\n",
    "    * Trial_Cluster: Variability at the neuron level (per trial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Formula:**\n",
    "\n",
    "$$\n",
    "\\text{percent\\_change\\_firing} \\sim \\text{Frequency\\_Hz} + (1 \\mid \\text{Rat\\_ID}) + \\{ \\text{Trial}: 0 + C(\\text{Trial\\_ID}),\\ \\text{Neuron}: 0 + C(\\text{Cluster}) \\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert variables to categorical types\n",
    "pre_post_pivot['Rat_ID']   = pre_post_pivot['Rat_ID'].astype('category')\n",
    "pre_post_pivot['Trial_ID'] = pre_post_pivot['Trial_ID'].astype('category')\n",
    "pre_post_pivot['cluster']  = pre_post_pivot['cluster'].astype('category')\n",
    "pre_post_pivot[\"percent_change\"] = pre_post_pivot[\"percent_change\"].astype('float')\n",
    "\n",
    "\n",
    "# Define variance components for trial and neuron (cluster)\n",
    "vc = {\n",
    "    'Trial': '0 + C(Trial_ID)',\n",
    "    'Neuron': '0 + C(cluster)',\n",
    "}\n",
    "\n",
    "# Specify the mixed effects model\n",
    "model = smf.mixedlm(\"percent_change ~ Frequency_Hz + voltage_bin\", pre_post_pivot, groups=pre_post_pivot[\"Rat_ID\"], vc_formula=vc)\n",
    "result = model.fit()\n",
    "\n",
    "# Display the model summary\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "things that could be possible:\n",
    "\n",
    "1. Multicollinearity - are Frequency and Voltage correlated?\n",
    "2. Trial_ID cluster have only than one level per group.\n",
    "3. Trial_ID cluster levels are not overly sparse or redundant with the fixed effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_post_pivot['Frequency_Hz'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_post_pivot['voltage_bin'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_post_pivot[['Frequency_Hz', 'voltage_bin']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, so these values are not highly correlated. this tells me we don't have enough data then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert variables to categorical types\n",
    "pre_post_pivot['Rat_ID']   = pre_post_pivot['Rat_ID'].astype('category')\n",
    "pre_post_pivot['Trial_ID'] = pre_post_pivot['Trial_ID'].astype('category')\n",
    "pre_post_pivot['cluster']  = pre_post_pivot['cluster'].astype('category')\n",
    "pre_post_pivot[\"percent_change\"] = pre_post_pivot[\"percent_change\"].astype('float')\n",
    "\n",
    "\n",
    "# Define variance components for trial and neuron (cluster)\n",
    "vc = {\n",
    "    'Trial': '0 + C(Trial_ID)',\n",
    "    'Neuron': '0 + C(Trial_ID):C(cluster)'  # neurons nested within trials\n",
    "}\n",
    "\n",
    "# Specify the mixed effects model\n",
    "model = smf.mixedlm(\"percent_change ~ Frequency_Hz\", pre_post_pivot, groups=pre_post_pivot[\"Rat_ID\"], vc_formula=vc)\n",
    "result = model.fit()\n",
    "\n",
    "# Display the model summary\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert variables to categorical types\n",
    "pre_post_pivot['Rat_ID']   = pre_post_pivot['Rat_ID'].astype('category')\n",
    "pre_post_pivot['Trial_ID'] = pre_post_pivot['Trial_ID'].astype('category')\n",
    "pre_post_pivot['cluster']  = pre_post_pivot['cluster'].astype('category')\n",
    "pre_post_pivot[\"percent_change\"] = pre_post_pivot[\"percent_change\"].astype('float')\n",
    "\n",
    "\n",
    "# Define variance components for trial and neuron (cluster)\n",
    "vc = {\n",
    "    'Neuron': 'C(cluster)'  # neurons nested within trials\n",
    "}\n",
    "\n",
    "# Specify the mixed effects model\n",
    "model = smf.mixedlm(\"percent_change ~ Frequency_Hz\", pre_post_pivot, groups=pre_post_pivot[\"Trial_ID\"], vc_formula=vc)\n",
    "result = model.fit()\n",
    "\n",
    "# Display the model summary\n",
    "print(result.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
